table_name,model,avg_valid_efficiency_score,avg_cell_precision,avg_cell_recall,avg_execution_accuracy,avg_tuple_cardinality,avg_tuple_constraint,avg_tuple_order
BMI,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.35445454545454547,0.3790909090909091,0.0,1.0,0.018181818181818184,0.5454545454545454
BMI,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.3376363636363636,0.3392727272727272,0.0,1.0,0.018181818181818184,0.5454545454545454
energy_consumption,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.6153846153846154,0.6153846153846154,0.5384615384615384,1.0,0.6153846153846154,0.8461538461538461
energy_consumption,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.46876923076923077,0.5206923076923077,0.3076923076923077,1.0,0.38461538461538464,0.7307692307692307
financial,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.317,0.31653333333333333,0.06666666666666667,1.0,0.09333333333333332,0.5966666666666666
financial,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.29066666666666663,0.2920666666666667,0.13333333333333333,0.6666666666666666,0.13333333333333333,0.36000000000000004
logistics_delivery,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.7555454545454545,0.8363636363636363,0.7272727272727273,1.0,0.7454545454545454,0.9090909090909091
logistics_delivery,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.49090909090909096,0.6545454545454545,0.2727272727272727,1.0,0.38181818181818183,0.7272727272727273
products,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.37829999999999997,0.5214000000000001,0.2,0.9,0.27999999999999997,0.5900000000000001
products,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.2262,0.4043,0.0,1.0,0.02,0.6
student_performance,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.6799999999999999,0.6866666666666668,0.6,1.0,0.67,0.8666666666666667
student_performance,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.392,0.48800000000000004,0.13333333333333333,1.0,0.24000000000000002,0.7
