table_name,model,avg_valid_efficiency_score,avg_cell_precision,avg_cell_recall,avg_execution_accuracy,avg_tuple_cardinality,avg_tuple_constraint,avg_tuple_order
accounts_receivable,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.4625714285714286,0.4342857142857143,0.03571428571428571,0.9035714285714286,0.32875,0.6370714285714286
accounts_receivable,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.22275,0.22925,0.0,0.5,0.13810714285714284,0.38010714285714287
breast_cancer,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.7082142857142857,0.7272142857142858,0.21428571428571427,0.9285714285714286,0.2785714285714286,0.712375
breast_cancer,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.38985714285714285,0.3985357142857143,0.17857142857142858,0.5,0.18571428571428572,0.375
fitness_trakers,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.5234642857142857,0.5549642857142857,0.10714285714285714,0.8928571428571429,0.18571428571428572,0.6071428571428571
fitness_trakers,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.3115,0.34735714285714286,0.07142857142857142,0.5,0.08214285714285714,0.3392857142857143
heart_attack,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.7686428571428571,0.7873214285714286,0.42857142857142855,0.9285714285714286,0.5428571428571428,0.8035714285714286
heart_attack,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.41414285714285715,0.42175,0.17857142857142858,0.5,0.3226071428571428,0.41326785714285713
mobiles,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.3423214285714286,0.3261785714285714,0.21428571428571427,0.42857142857142855,0.23860714285714285,0.39285714285714285
mobiles,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.4821785714285714,0.5002857142857142,0.17857142857142858,0.5714285714285714,0.35882142857142857,0.4467678571428571
olympic_games,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.889,1.0,0.75,0.9,1.0,0.928625
olympic_games,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.5,0.5,0.25,0.4,0.3,0.133875
