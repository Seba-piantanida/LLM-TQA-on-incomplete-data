table_name,model,avg_valid_efficiency_score,avg_cell_precision,avg_cell_recall,avg_execution_accuracy,avg_tuple_cardinality,avg_tuple_constraint,avg_tuple_order
accounts_receivable,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.46503571428571433,0.4720714285714286,0.0,1.0,0.3625,0.7464285714285713
accounts_receivable,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.4670714285714285,0.4774285714285714,0.0,1.0,0.3017857142857143,0.7321428571428571
breast_cancer,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.8271428571428572,0.8391071428571429,0.42857142857142855,1.0,0.5339285714285714,0.8214285714285714
breast_cancer,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.6883214285714285,0.7255,0.2857142857142857,1.0,0.3535714285714286,0.7142857142857143
fitness_trakers,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.5126071428571428,0.6459285714285714,0.10714285714285714,0.8928571428571429,0.2333214285714286,0.6785714285714286
fitness_trakers,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.6046071428571428,0.6165,0.21428571428571427,1.0,0.2238214285714286,0.6428571428571429
heart_attack,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.8677857142857144,0.87675,0.6785714285714286,1.0,0.7000000000000001,0.875
heart_attack,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.7872857142857143,0.7807142857142857,0.42857142857142855,1.0,0.6285714285714287,0.8392857142857143
mobiles,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.7203571428571429,0.6854642857142857,0.4642857142857143,0.9285714285714286,0.5285714285714286,0.7357142857142858
mobiles,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.6751071428571428,0.6854285714285714,0.32142857142857145,1.0,0.5053571428571428,0.7553571428571428
olympic_games,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.96675,0.96675,0.75,1.0,0.95,1.0
olympic_games,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.96425,0.9,0.5,1.0,0.85,0.7
