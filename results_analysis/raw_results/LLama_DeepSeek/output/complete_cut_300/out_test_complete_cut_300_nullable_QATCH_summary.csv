table_name,model,avg_valid_efficiency_score,avg_cell_precision,avg_cell_recall,avg_execution_accuracy,avg_tuple_cardinality,avg_tuple_constraint,avg_tuple_order
accounts_receivable,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.23792857142857143,0.23214285714285715,0.0,0.9642857142857143,0.014285714285714287,0.5178571428571429
accounts_receivable,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.28782142857142856,0.27332142857142855,0.0,1.0,0.02142857142857143,0.5178571428571429
breast_cancer,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.45914285714285713,0.4860357142857143,0.07142857142857142,0.9642857142857143,0.11607142857142858,0.6071428571428571
breast_cancer,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.5245714285714286,0.52175,0.21428571428571427,1.0,0.24285714285714285,0.625
fitness_trakers,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.33835714285714286,0.3542142857142857,0.0,1.0,0.0,0.5178571428571429
fitness_trakers,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.3732857142857143,0.38471428571428573,0.03571428571428571,1.0,0.049999999999999996,0.5535714285714286
heart_attack,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.44382142857142853,0.4416785714285714,0.03571428571428571,1.0,0.1285714285714286,0.6428571428571429
heart_attack,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.627,0.5425714285714286,0.14285714285714285,1.0,0.2785714285714286,0.75
mobiles,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.4626428571428572,0.4363214285714286,0.17857142857142858,0.9285714285714286,0.19999999999999998,0.5892857142857143
mobiles,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.41867857142857146,0.41942857142857143,0.07142857142857142,1.0,0.14464285714285713,0.5714285714285714
olympic_games,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.276,0.276,0.0,1.0,0.0,0.5
olympic_games,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.31174999999999997,0.31174999999999997,0.0,1.0,0.0,0.5
