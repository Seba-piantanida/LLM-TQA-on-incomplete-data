table_name,model,avg_valid_efficiency_score,avg_cell_precision,avg_cell_recall,avg_execution_accuracy,avg_tuple_cardinality,avg_tuple_constraint,avg_tuple_order
accounts_receivable,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.27182142857142855,0.26382142857142854,0.0,0.9642857142857143,0.021428571428571432,0.5
accounts_receivable,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.19664285714285715,0.18632142857142855,0.0,0.8928571428571429,0.0071428571428571435,0.44642857142857145
breast_cancer,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.23467857142857146,0.4386785714285714,0.0,0.8214285714285714,0.0,0.4107142857142857
breast_cancer,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.26757142857142857,0.48817857142857146,0.0,1.0,0.0,0.5
fitness_trakers,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.3052142857142857,0.35435714285714287,0.03571428571428571,0.8714285714285713,0.03571428571428571,0.44642857142857145
fitness_trakers,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.2675,0.296,0.0,1.0,0.0,0.5
heart_attack,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.3856428571428571,0.6351428571428571,0.03571428571428571,1.0,0.08571428571428572,0.5
heart_attack,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.3735714285714286,0.6025357142857143,0.03571428571428571,1.0,0.12142857142857143,0.5357142857142857
mobiles,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.37589285714285714,0.3704642857142857,0.0,0.8928571428571429,0.07142857142857142,0.44642857142857145
mobiles,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.3597142857142857,0.37785714285714284,0.03571428571428571,0.8928571428571429,0.14939285714285713,0.48214285714285715
olympic_games,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.34275,0.276,0.0,1.0,0.0,0.5
olympic_games,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.276,0.276,0.0,1.0,0.0,0.5
