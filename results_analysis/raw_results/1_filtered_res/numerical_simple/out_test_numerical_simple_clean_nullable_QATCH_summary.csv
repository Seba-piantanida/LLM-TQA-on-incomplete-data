table_name,model,avg_valid_efficiency_score,avg_cell_precision,avg_cell_recall,avg_execution_accuracy,avg_tuple_cardinality,avg_tuple_constraint,avg_tuple_order
BMI,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.048,0.048,0.0,1.0,0.0,0.5
BMI,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.0865,0.0865,0.0,1.0,0.0,0.5
energy_consumption,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.475,0.475,0.25,1.0,0.425,0.75
energy_consumption,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.471375,0.471375,0.25,1.0,0.35,0.6875
financial,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.0,0.0,0.0,1.0,0.0,0.5
financial,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.0,0.0,0.0,1.0,0.0,0.5
logistics_delivery,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.42857142857142855,0.42857142857142855,0.2857142857142857,1.0,0.42857142857142855,0.7857142857142857
logistics_delivery,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.39999999999999997,0.39999999999999997,0.2857142857142857,1.0,0.39999999999999997,0.7142857142857143
products,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.0,0.0,0.0,1.0,0.0,0.5
products,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.0,0.0,0.0,1.0,0.0,0.5
student_performance,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.42857142857142855,0.42857142857142855,0.42857142857142855,1.0,0.42857142857142855,0.7142857142857143
student_performance,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.39999999999999997,0.39999999999999997,0.2857142857142857,1.0,0.39999999999999997,0.7142857142857143
