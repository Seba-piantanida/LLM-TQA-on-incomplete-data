table_name,model,avg_valid_efficiency_score,avg_cell_precision,avg_cell_recall,avg_execution_accuracy,avg_tuple_cardinality,avg_tuple_constraint,avg_tuple_order
accounts_receivable,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.13967857142857143,0.03596428571428571,0.0,0.3453928571428571,0.002857142857142857,0.26785714285714285
accounts_receivable,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.0,0.0,0.0,0.14014285714285715,0.0,0.07142857142857142
breast_cancer,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.20142857142857146,0.11510714285714285,0.0,0.40864285714285714,0.02182142857142857,0.2855535714285714
breast_cancer,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.14285714285714285,0.07653571428571428,0.03571428571428571,0.17857142857142858,0.03571428571428571,0.16071428571428573
fitness_trakers,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.22867857142857145,0.10667857142857143,0.0,0.3718214285714286,0.020464285714285713,0.33992857142857147
fitness_trakers,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.03571428571428571,0.002214285714285714,0.0,0.2369642857142857,0.0,0.14285714285714285
heart_attack,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.15714285714285717,0.10117857142857144,0.0,0.35382142857142856,0.0,0.26785714285714285
heart_attack,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.07142857142857142,0.03571428571428571,0.0,0.10392857142857144,0.0,0.08928571428571429
mobiles,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.10135714285714285,0.046142857142857145,0.0,0.31871428571428567,0.0,0.23214285714285715
mobiles,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.07142857142857142,0.03571428571428571,0.0,0.16964285714285715,0.0,0.125
olympic_games,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.353,0.353,0.0,0.95825,0.0,0.5
olympic_games,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.1765,0.1765,0.0,0.5,0.0,0.25
