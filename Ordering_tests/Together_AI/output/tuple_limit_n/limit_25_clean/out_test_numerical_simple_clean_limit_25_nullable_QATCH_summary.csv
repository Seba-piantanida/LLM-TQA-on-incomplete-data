table_name,model,avg_valid_efficiency_score,avg_cell_precision,avg_cell_recall,avg_execution_accuracy,avg_tuple_cardinality,avg_tuple_constraint,avg_tuple_order
BMI,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.369,0.5425,0.0,0.953,0.20650000000000002,0.875
BMI,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.16725,0.18475,0.0,0.6945,0.0,0.375
energy_consumption,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.155,0.155,0.125,0.69775,0.155,0.46875
energy_consumption,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.37,0.37,0.25,0.602375,0.37,0.5
financial,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.0,0.0,0.0,0.926,0.0,0.5
financial,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.0,0.0,0.0,0.0,0.0,0.0
logistics_delivery,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.47214285714285714,0.47285714285714286,0.2857142857142857,0.7891428571428571,0.46571428571428575,0.7102142857142857
logistics_delivery,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.2952857142857143,0.29714285714285715,0.14285714285714285,0.5408571428571428,0.29714285714285715,0.5
products,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.0,0.0,0.0,0.981,0.0,0.5
products,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.0,0.0,0.0,0.4465,0.0,0.25
student_performance,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.5381428571428571,0.559,0.42857142857142855,0.9257142857142858,0.528,0.7770714285714285
student_performance,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.31685714285714284,0.3297142857142857,0.14285714285714285,0.6607142857142857,0.3172857142857143,0.5714285714285714
