table_name,model,avg_valid_efficiency_score,avg_cell_precision,avg_cell_recall,avg_execution_accuracy,avg_tuple_cardinality,avg_tuple_constraint,avg_tuple_order
BMI,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.93775,0.96075,0.5,0.9904999999999999,0.9095,0.97275
BMI,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.65225,0.72175,0.25,0.7315,0.66225,0.744125
energy_consumption,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.71075,0.72,0.375,0.74075,0.72,0.74975
energy_consumption,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.625,0.61,0.5,0.61,0.61,0.625
financial,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,1.0,0.333,0.0,1.0,0.0,1.0
financial,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,1.0,1.0,0.0,0.962,0.0,1.0
logistics_delivery,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.6541428571428571,0.7300000000000001,0.2857142857142857,0.7595714285714286,0.722857142857143,0.8571428571428571
logistics_delivery,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.5458571428571428,0.5599999999999999,0.2857142857142857,0.5455714285714286,0.5528571428571428,0.5714285714285714
products,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,1.0,1.0,1.0,1.0,1.0,1.0
products,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.75,1.0,0.0,0.894,0.25,1.0
student_performance,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.9714285714285714,0.9938571428571429,0.7142857142857143,0.9847142857142857,0.8324285714285714,1.0
student_performance,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.5171428571428571,0.559,0.14285714285714285,0.519,0.4875714285714286,0.5714285714285714
