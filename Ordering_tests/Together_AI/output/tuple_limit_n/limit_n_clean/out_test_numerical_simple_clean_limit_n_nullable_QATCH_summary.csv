table_name,model,avg_valid_efficiency_score,avg_cell_precision,avg_cell_recall,avg_execution_accuracy,avg_tuple_cardinality,avg_tuple_constraint,avg_tuple_order
BMI,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.0,0.0,0.0,0.0,0.0,0.0
BMI,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.19825,0.204,0.0,0.7,0.0,0.375
energy_consumption,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.013875,0.015,0.0,0.3365,0.015,0.25
energy_consumption,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.5091249999999999,0.51,0.25,0.86075,0.385,0.59375
financial,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.0,0.0,0.0,0.3,0.0,0.5
financial,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.0,0.0,0.0,0.0,0.0,0.0
logistics_delivery,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.7388571428571428,0.2857142857142857,0.5714285714285714
logistics_delivery,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.3028571428571429,0.3028571428571429,0.14285714285714285,0.7088571428571429,0.3028571428571429,0.5714285714285714
products,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.0,0.0,0.0,0.9665,0.0,0.5
products,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.0,0.0,0.0,0.933,0.0,0.5
student_performance,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.12085714285714286,0.1367142857142857,0.0,0.40757142857142853,0.1367142857142857,0.2857142857142857
student_performance,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.4561428571428571,0.46628571428571425,0.2857142857142857,0.9455714285714285,0.46014285714285713,0.7857142857142857
