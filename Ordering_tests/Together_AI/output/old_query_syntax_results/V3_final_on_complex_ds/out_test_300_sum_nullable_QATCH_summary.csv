table_name,model,avg_valid_efficiency_score,avg_cell_precision,avg_cell_recall,avg_execution_accuracy,avg_tuple_cardinality,avg_tuple_constraint,avg_tuple_order
accounts_receivable,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.244,0.2329642857142857,0.0,0.9642857142857143,0.0071428571428571435,0.5
accounts_receivable,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.2583214285714286,0.24667857142857144,0.0,1.0,0.0,0.5
breast_cancer,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.3364285714285714,0.4538214285714286,0.0,1.0,0.0071428571428571435,0.5178571428571429
breast_cancer,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.3513928571428572,0.5763214285714285,0.03571428571428571,1.0,0.03571428571428571,0.5178571428571429
fitness_trakers,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.43464285714285716,0.4451428571428572,0.03571428571428571,1.0,0.07142857142857142,0.5535714285714286
fitness_trakers,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.3922857142857143,0.4303571428571429,0.03571428571428571,1.0,0.03571428571428571,0.5178571428571429
heart_attack,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.5455714285714286,0.657,0.17857142857142858,0.9928571428571429,0.2357142857142857,0.7321428571428571
heart_attack,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.5677142857142857,0.6493571428571429,0.14285714285714285,1.0,0.25357142857142856,0.6964285714285714
mobiles,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.47846428571428573,0.4759285714285714,0.07142857142857142,1.0,0.07857142857142858,0.5535714285714286
mobiles,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.38689285714285715,0.42200000000000004,0.03571428571428571,1.0,0.10892857142857142,0.5535714285714286
olympic_games,deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free,0.0,0.28974999999999995,0.31174999999999997,0.0,0.95825,0.0,0.5
olympic_games,meta-llama/Llama-3.3-70B-Instruct-Turbo-Free,0.0,0.276,0.276,0.0,1.0,0.0,0.5
